# Bandits
Piloto de bandits sin contexto, recompenss bernouilli, gaussiana y categorica

# Bandits
Implementaci√≥n completa de un sistema de *multi‚Äëarmed bandits* sin contexto, con soporte para recompensas **Bernoulli**, **Gaussianas** y **Categ√≥ricas**, incluyendo m√∫ltiples pol√≠ticas, m√©tricas avanzadas y un runner configurable para experimentaci√≥n.

Este proyecto sirve como piloto para estudiar el comportamiento de distintas familias de bandits y comparar pol√≠ticas cl√°sicas como **UCB**, **Thompson Sampling** y **Boltzmann/Softmax** en entornos con distribuciones de recompensa diferentes.

---

## üöÄ Caracter√≠sticas principales

- **Tres tipos de bandits**:
  - **Bernoulli** (√©xito/fracaso)
  - **Gaussiano** (recompensa continua)
  - **Categ√≥rico** (recompensa discreta multinomial)

- **Pol√≠ticas implementadas**:
  - **UCB** (Upper Confidence Bound)
  - **Thompson Sampling**
  - **Boltzmann / Softmax**
  - Variantes espec√≠ficas para cada tipo de bandit

- **Runner general** para ejecutar simulaciones:
  - Control de n√∫mero de iteraciones
  - Criterios de parada (incluyendo entrop√≠a del *slate*)
  - Registro de m√©tricas
  - Comparaci√≥n entre pol√≠ticas

- **M√©tricas avanzadas**:
  - Regret acumulado
  - Estabilidad del *slate*
  - N√∫mero efectivo de brazos (entrop√≠a)
  - Variaci√≥n relativa de medias
  - Convergencia por batches
  - Tiempos de ejecuci√≥n (policy, replay, total)

- **Soporte para slates** (selecci√≥n de varios brazos por iteraci√≥n)

